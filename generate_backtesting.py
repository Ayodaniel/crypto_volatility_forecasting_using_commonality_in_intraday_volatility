import concurrent.futures
import datetime
import glob
import pdb
import pandas as pd
import numpy as np
from typing import Tuple
from dateutil.relativedelta import relativedelta
import plotly.express as px
from plotly.subplots import make_subplots
from data_centre.data import DBQuery
import os
from data_centre.data import OptionChainData
from model.lab import qlike_score
import argparse
from arch import arch_model
from data_centre.data import Reader
""" Silence warning generated by GARCH model training"""
from arch.__future__ import reindexing
reindexing = True
from model.lab import training_freq


class OptionTrader:

    reader_obj = Reader()

    def __init__(self, fees: float):
        self._fees = fees
        self._pricing_model = None

    @property
    def fees(self) -> float:
        return self._fees

    @property
    def pricing_model(self) -> str:
        return self._pricing_model

    @fees.setter
    def fees(self, fees: float) -> None:
        self._fees = fees

    @pricing_model.setter
    def pricing_model(self, pricing_model: str) -> None:
        self._pricing_model = pricing_model

    def process_mkt_data(self, data: pd.DataFrame, option_type: str = 'call') -> pd.DataFrame:
        mkt_data = data.loc[data.index.get_level_values(1) == f'{option_type}', :]
        return mkt_data

    def add_pnl(self, data: pd.DataFrame) -> pd.DataFrame:
        data['d_iv'] = data.groupby(by=[pd.Grouper(level='option_tag')])[['mark_iv']].diff()
        data['d_underlying'] = data.groupby(by=[pd.Grouper(level='option_tag')])[['underlying_price']].diff()
        data['d_underlying2'] = data['d_underlying'] ** 2
        data['d_t'] = data.index.get_level_values(-1).copy()
        data['d_t'] = data.groupby(by=[pd.Grouper(level='option_tag')], group_keys=False).apply(
            lambda x: x.d_t.diff() / pd.to_timedelta('360D'))
        data['PnL'] = data['theta'] * data['d_t'] + data['delta'] * data['d_underlying'] + \
                      data['vega'] * data['d_iv'] + .5 * data['gamma'] * data['d_underlying2']
        return data

    def pivot(self, mkt_data: pd.DataFrame, h: str) -> Tuple[pd.DataFrame]:
        ls = list()
        index = pd.to_datetime(pd.date_range(start='2021-01-01', end='2023-07-01', freq=h, inclusive='left'),
                               utc=True)
        for col in ['strike_price', 'mark_price', 'underlying_price', 'delta',
                    'gamma', 'vega', 'theta', 'rho', 'expiration', 'dt', 'mark_iv']:
            if col == 'dt':
                tmp = pd.DataFrame(index=tmp.index, columns=tmp.columns, data=np.nan)
                tmp.iloc[1:, 0] = (tmp.index[1:] - tmp.index[0:-1]) / pd.to_timedelta('360D')
                tmp = tmp.ffill(axis=1)
            else:
                tmp = pd.pivot_table(mkt_data.reset_index(), index='timestamp', columns='option_tag', values=col)
                tmp = tmp.reindex(index)
                tmp = tmp.ffill()
                if col == 'expiration':
                    tmp = tmp.bfill()
                    tmp = tmp.subtract(tmp.index, axis=0)/pd.to_timedelta('360D')
                    tmp = tmp.where(tmp > 0, np.nan)
            ls.append(tmp)
        return tuple(ls)

    def fit_garch(self, date: datetime.datetime, L_train: dict, L: str, returns: pd.DataFrame,
                  GARCH: pd.DataFrame) -> None:
        start = (date - relativedelta(days=L_train[L])).strftime('%Y-%m-%d')
        print(f'[Start Training]: GARCH model^{L} training on {date} has started.')
        GARCH_model = arch_model(y=returns.loc[start:date.strftime('%Y-%m-%d')].values.reshape(-1),
                                 vol='GARCH', p=1, q=1, mean='Constant', rescale=True)
        GARCH_model = GARCH_model.fit(update_freq=0, disp=False)
        rv_hat = \
            GARCH_model.forecast(horizon=pd.to_timedelta('1D') // pd.to_timedelta(h)).variance.values[-1, :]
        rv_hat = rv_hat.reshape(rv_hat.shape[0], 1) / GARCH_model.scale ** 2
        GARCH.loc[date.strftime('%Y-%m-%d'):date.strftime('%Y-%m-%d')] = rv_hat
        print(f'[End of Training]: GARCH model^{L} training on {date} has been completed.')


if __name__ == '__main__':

    parser = argparse.ArgumentParser(description='Script backtesting option trading strategies.')
    parser.add_argument('--liquidity', default=.75, type=float, help='Threshold of liquid to keep for backtesting.')
    parser.add_argument('--performance', default='returns', type=str,
                        help='Ways to compute P&L: greeks or return based.')
    parser.add_argument('--min_expiration', type=str, help='Minimum expiration to filter option chain data.',
                        default='7D')
    parser.add_argument('--max_expiration', type=str, help='Maximum expiration to filter option chain data.',
                        default='180D')
    parser.add_argument('--min_moneyness', type=float, help='Minimum moneyness to filter option chain data.',
                        default=.85)
    parser.add_argument('--max_moneyness', type=float, help='Maximum moneyness to filter option chain data.',
                        default=1.15)
    parser.add_argument('--to_latex', type=int, help='Print out final table as LaTeX table or not.',
                        default=0)
    parser.add_argument('--h', type=str, help='Time interval.', default='30T')
    parser.add_argument('--save', type=int, help='Save or show figures.', default=1)
    args = parser.parse_args()
    index = pd.to_datetime(pd.date_range(start='2021-01-01', end='2023-07-01', freq=args.h, inclusive='left'), utc=True)
    print(args)
    liquidity = args.liquidity
    min_moneyness = args.min_moneyness
    max_moneyness = args.max_moneyness
    db_obj = DBQuery()
    option_trader_obj = OptionTrader(fees=.0004)
    option_chain_data_obj = OptionChainData()
    files = [file for file in glob.glob('../data_centre/tmp/datasets/*-*-*')]
    data = pd.concat([pd.read_parquet(option_chain) for option_chain in files])
    data = data.assign(moneyness=data.underlying_price.div(data.strike_price))
    data['volume'] = data.volume*data.mark_price*data.underlying_price
    liquidity = data['volume'].quantile(liquidity)
    data = \
        data.query(
            f'volume >= {liquidity} & moneyness >= {min_moneyness} & moneyness <= {max_moneyness}').drop(['volume',
                                                                                                          'moneyness'],
                                                                                                         axis=1)
    data = data.set_index('type', append=True).swaplevel(i=1, j=-1)
    data = data.assign(time2expiration=(data.expiration-data.index.get_level_values(-1))/pd.to_timedelta('360D'))
    data = data.query(f'time2expiration >= {pd.to_timedelta(args.min_expiration)/pd.to_timedelta("360D")} &'
                      f'time2expiration <= {pd.to_timedelta(args.max_expiration)/pd.to_timedelta("360D")}')
    calls, puts = option_trader_obj.process_mkt_data(data=data),\
        option_trader_obj.process_mkt_data(data=data, option_type='put')
    returns = option_trader_obj.reader_obj.returns_read(symbol='ETHUSDT').replace(0, np.nan)
    returns = returns.fillna(returns.ewm(span=12, min_periods=1).mean())
    rv = option_trader_obj.reader_obj.rv_read(symbol='ETHUSDT')
    if args.performance == 'greeks':
        calls_strike_price, calls_mark_price, calls_underlying_price, calls_delta, \
        calls_gamma, calls_vega, calls_theta, calls_rho, calls_expiration, calls_dt, calls_mark_iv = \
            option_trader_obj.pivot(calls, args.h)
        puts_strike_price, puts_mark_price, puts_underlying_price, puts_delta, \
            puts_gamma, puts_vega, puts_theta, puts_rho, puts_expiration, puts_dt, puts_mark_iv = \
            option_trader_obj.pivot(puts, args.h)
        calls_PnL = calls_theta * calls_dt + calls_delta * calls_underlying_price.diff() + \
                    calls_vega * calls_mark_iv + .5 * calls_gamma * calls_underlying_price.diff() ** 2
        puts_PnL = puts_theta * puts_dt + puts_delta * puts_underlying_price.diff() + puts_vega * puts_mark_iv + \
                    .5 * puts_gamma * puts_underlying_price.diff() ** 2
    elif args.performance == 'returns':
        calls_strike_price, calls_mark_price, calls_underlying_price, _, _, _, _, _, calls_expiration, calls_dt,\
            calls_mark_iv = option_trader_obj.pivot(calls, args.h)
        puts_strike_price, puts_mark_price, puts_underlying_price, _, _, _, _, _, puts_expiration, puts_dt,\
            puts_mark_iv = option_trader_obj.pivot(puts, args.h)
        calls_PnL, puts_PnL = np.log(calls_mark_price.div(calls_mark_price.shift())),\
            np.log(puts_mark_price.div(puts_mark_price.shift()))
    straddle_ls = list(set(calls_PnL.columns).intersection(set(puts_PnL.columns)))
    # PnL = calls_PnL.filter(regex=f'{"|".join(straddle_ls)}') + puts_PnL.filter(regex=f'{"|".join(straddle_ls)}')
    PnL = \
        calls_mark_price.filter(regex=f'{"|".join(straddle_ls)}') + \
        puts_mark_price.filter(regex=f'{"|".join(straddle_ls)}')
    straddles = (calls_PnL.filter(regex=f'{"|".join(straddle_ls)}').fillna(0) != 0) + \
                (puts_PnL.filter(regex=f'{"|".join(straddle_ls)}').fillna(0) != 0)
    PnL = np.log(PnL.div(PnL.shift())).replace(0, np.nan)
    PnL = (PnL - np.abs(PnL) * option_trader_obj.fees).mean(axis=1)
    qlike = \
        db_obj.query_data(db_obj.best_model_for_all_windows_query('qlike'), table='qlike').sort_values(by='L',
                                                                                                       ascending=True)
    suffix_name = \
        {'trading_session': {True: 'eq', False: 'eq_vixm'}, 'top_book': {True: 'top_book', False: 'full_book'}}
    PnL_per_strat = dict()
    trades_per_strat = dict()
    rv_models = dict()
    qlike_models = dict()
    rv_GARCH = dict()
    qlike_GARCH = dict()
    L_train = {'1W': 7, '1M': 30, '6M': 180}
    for idx1, row in qlike.iterrows():
        L = row['L']
        model, regression, training_scheme, trading_session, top_book, h = row['model'], row['regression'], \
            row['training_scheme'], row['trading_session'], row['top_book'], row['h']
        y_hat = db_obj.forecast_query(L=L, model=model, regression=regression, trading_session=trading_session,
                                      top_book=top_book, training_scheme=training_scheme)[['y_hat', 'symbol']]
        perf = db_obj.forecast_performance(L=L, model=model, regression=regression, training_scheme=training_scheme,
                                           trading_session=trading_session, top_book=top_book)
        y_hat = y_hat.query('symbol == "ETHUSDT"')
        y_hat = pd.pivot(data=y_hat, columns='symbol', values='y_hat')
        y_hat.index = pd.to_datetime(y_hat.index)
        y_hat = y_hat.resample(h).sum()
        y_hat = y_hat.rename(columns={'ETHUSDT': 'sig'})
        rv_models[('$\mathcal{M}$', L.lower())] = y_hat
        qlike_models[('$\mathcal{M}$', L.lower())] = \
            perf.query('symbol=="ETHUSDT"')[['values']].rename(columns={'values': ('$\mathcal{M}$', L.lower())})
        dates = list(set(np.unique(y_hat.index.date).tolist()))
        dates.sort()
        ################################################################################################################
        ### Fitting GARCH(1,1)
        ################################################################################################################
        GARCH = pd.DataFrame(index=pd.date_range(start=returns.index[0].date(),
                                                 end=returns.index[-1].date()+relativedelta(days=1),
                                                 freq=h, inclusive='left'), columns=['sig'], data=np.nan)
        GARCH.index = pd.to_datetime(GARCH.index, utc=True)
        with concurrent.futures.ThreadPoolExecutor() as executor:
            futures = [executor.submit(option_trader_obj.fit_garch, date=date,
                                       returns=returns.loc[y_hat.index],
                                       L_train=L_train, L=L, GARCH=GARCH) for date in dates]
        rv_GARCH[('GARCH', L.lower())] = GARCH
        qlike_models[('GARCH', L.lower())] = \
            pd.DataFrame(pd.concat([rv.resample(h).sum(), GARCH],
                                   axis=1).loc[y_hat.index, :].resample('1W')[['ETHUSDT', 'sig']].apply(qlike_score),
                         columns=[('GARCH', L.lower())])
    # perf_qlike = pd.DataFrame()
    # for _, perf in qlike_models.items():
    #     if perf_qlike.empty:
    #         perf_qlike = perf.copy()
    #     else:
    #         perf_qlike = perf_qlike.join(perf, how='outer')
    # perf_qlike.columns = pd.MultiIndex.from_tuples(perf_qlike.sort_index(axis=1).columns)
    # perf_qlike = perf_qlike.loc[perf_qlike.index.duplicated(), :]
    # pdb.set_trace()
    # if L == '6M':
    #     pdb.set_trace()
    #     pd.concat(qlike_models.values(), axis=1).sort_index(axis=1)
    # pdb.set_trace()
    # qlike_models = pd.concat(qlike_models.values()).sort_index(axis=1)
    ########################################################################################################
    ### Signals
    ########################################################################################################
    signals = \
        pd.concat(rv_models, axis=1).droplevel(axis=1, level=2).join(pd.concat(rv_GARCH, axis=1).droplevel(axis=1,
                                                                                                           level=2))**.5
    signals = np.sign(signals.diff()).fillna(0).astype(int)
    signals = signals.apply(lambda x: x.where(x != x.shift(), 0)).shift()
    signals = signals.reindex(index)
    PnL_per_strat = signals.apply(lambda x, y: x*y, y=PnL).resample('1D')
    ethPnL = pd.DataFrame(data=np.nan, index=PnL_per_strat.indices.keys(),
                          columns=pd.MultiIndex.from_product([['ETH'],
                                                              signals.columns.get_level_values(1).unique().tolist()]))
    ethPnL.iloc[:, 0] = returns.resample('1D').sum().values
    ethPnL.loc[ethPnL.iloc[:, 0].first_valid_index()] = \
        ethPnL.loc[ethPnL.iloc[:, 0].first_valid_index()]-.001*np.abs(ethPnL.loc[ethPnL.iloc[:, 0].first_valid_index()])
    ethPnL = ethPnL.ffill(axis=1)
    ethPnL.loc[:signals.apply(lambda x:x.first_valid_index())[0], :] = 0
    PnL_per_strat = pd.concat([PnL_per_strat.sum(), ethPnL], axis=1)
    Bt = np.abs(signals.apply(lambda x, y: x*y.sum(axis=1), y=straddles).resample('1D').sum())
    Tt = np.abs(signals).sum(axis=1).resample('1D').sum()
    PPD_per_strat = PnL_per_strat.iloc[:, :-3].sum().div(Bt).replace(-np.inf, np.nan).replace(np.inf, np.nan).mean()
    PPT_per_strat = PnL_per_strat.iloc[:, :-3].apply(lambda x, y: x.div(y), y=Tt).replace(np.inf, np.nan).mean()
    ################################################################################################################
    ### Backtesting
    ################################################################################################################
    sharpeRatio = \
        PnL_per_strat.mean().div(PnL_per_strat.std()).replace(np.inf, np.nan).replace(-np.inf, np.nan).dropna(
            how='all').mul(np.sqrt(360)).reset_index().rename(
            columns={'level_0': 'Strategy', 'level_1': r'$L_{train}$', 0: 'Sharpe ratio'})
    sharpeRatio[r'$L_{train}$'] = [f'${L.lower()}$' for L in sharpeRatio[r'$L_{train}$']]
    sharpeRatio['Strategy'] = [model.upper().replace('_', ' ') if model in ['GARCH']
                               else model for model in sharpeRatio['Strategy']]
    print(f'Option universe size: {straddles.shape[1]}.\n')
    print('---------Sharpe ratio table-------------')
    print(sharpeRatio)
    print('---------******************-------------\n')
    print('---------P&L per strategy table-------------')
    print(PnL_per_strat.add(1).cumprod())
    print('---------**********************-------------\n')
    print('---------PPD table-------------')
    PPD_per_strat = PPD_per_strat.reset_index().set_index(['level_0', 'level_1']).transpose()
    PPD_per_strat.columns.names = [None, None]
    PPD_per_strat = PPD_per_strat.loc[:, [('GARCH', '1w'), ('GARCH', '1m'), ('GARCH', '6m'),
                                          (r'$\mathcal{M}$', '1w'), (r'$\mathcal{M}$', '1m'), (r'$\mathcal{M}$', '6m')]]
    PPD_per_strat = PPD_per_strat.dropna(axis=1)
    print(PPD_per_strat)
    print('---------*********-------------\n')
    print('---------PPT table-------------')
    PPT_per_strat = PPT_per_strat.reset_index().set_index(['level_0', 'level_1']).transpose()
    PPT_per_strat.columns.names = [None, None]
    PPT_per_strat = PPT_per_strat.loc[:, [('GARCH', '1w'), ('GARCH', '1m'), ('GARCH', '6m'),
                                          (r'$\mathcal{M}$', '1w'), (r'$\mathcal{M}$', '1m'), (r'$\mathcal{M}$', '6m')]]
    PPT_per_strat = PPT_per_strat.dropna(axis=1)
    print(PPT_per_strat)
    print('---------*********-------------\n')
    PnL_per_strat = PnL_per_strat.fillna(0).cumsum()
    PnL_per_strat = PnL_per_strat.unstack().reset_index().rename(columns={'level_0': 'Strategy',
                                                                          'level_1': r'$L_{train}$',
                                                                          0: 'PnL'})
    PnL_per_strat[r'$L_{train}$'] = [f'${L.lower()}$' for L in PnL_per_strat[r'$L_{train}$']]
    PnL_per_strat['Strategy'] = [model.upper().replace('_', ' ') if model in ['GARCH'] else model
                                 for model in PnL_per_strat['Strategy']]
    PnL_per_strat = PnL_per_strat.rename(columns={'level_2': 'timestamp'})
    numberTrades = dict()
    for i in range(0, signals.shape[1]):
        numberTrades[signals.columns[i]] = \
            straddles.apply(lambda x, y: x * y, y=signals.iloc[:, i]).fillna(0).apply(
                lambda x: x.value_counts()).drop(0.0).sum(axis=1)
    numberTrades = pd.concat(numberTrades, axis=1).fillna(0).astype(int)
    numberTrades = numberTrades.loc[:, [('GARCH', '1w'), ('GARCH', '1m'), ('GARCH', '6m'),
                                        (r'$\mathcal{M}$', '1w'), (r'$\mathcal{M}$', '1m'),
                                        (r'$\mathcal{M}$', '6m')]]
    print('---------Number of trade table-------------')
    print(numberTrades)
    print('---------*********************-------------\n')
    ####################################################################################################################
    ## Figure 1: Sharpe ratio
    ####################################################################################################################
    fig = px.bar(sharpeRatio, x=r'$L_{train}$', y='Sharpe ratio', color='Strategy', barmode='group',
                 title='Annualized Sharpe ratio', text_auto='.2f',
                 category_orders={'$L_{train}$': [r'$1w$', r'$1m$', r'$6m$'],
                                  'Strategy': ['ETH', 'GARCH', r'$\mathcal{M}$']})
    fig.update_layout(width=1_200)
    ####################################################################################################################
    ## Figure 2: PnL per strat
    ####################################################################################################################
    fig2 = make_subplots(rows=PnL_per_strat[r'$L_{train}$'].unique().shape[0], cols=1,
                         shared_xaxes=True, shared_yaxes=False, row_titles=[r'$1w$', r'$1m$', r'$6m$'],
                         vertical_spacing=.5/PnL_per_strat['$L_{train}$'].unique().shape[0])
    tmp_fig = px.line(PnL_per_strat, x='timestamp', y='PnL', color='Strategy', facet_row=r'$L_{train}$',
                      category_orders={'$L_{train}$': [r'$1w$', r'$1m$', r'$6m$'],
                                       'Strategy': ['ETH', 'GARCH', '$\mathcal{M}$']}, facet_row_spacing=.1)
    for i in range(0, len(tmp_fig.data), 3):
        fig2.add_trace(trace=tmp_fig.data[i], col=1, row=1)
        fig2.add_trace(trace=tmp_fig.data[i + 1], col=1, row=2)
        fig2.add_trace(trace=tmp_fig.data[i + 2], col=1, row=3)
    fig2.update_xaxes(title_text='Date', tickangle=45, row=3)
    fig2.update_yaxes(title_text='PnL')
    fig2.update_layout(title_text=f'Cumulative P&L curves', width=1_200, height=800)
    if args.save == 1:
        fig.write_image(os.path.abspath(f'../figures/sharpe_ratio_{args.performance}.pdf'))
        print(f'[Figures]: Sharpe ratio has been saved.')
        fig2.write_image(os.path.abspath(f'../figures/pnl_{args.performance}.pdf'))
        print(f'[Figures]: PnL has been saved.')
    else:
        fig.show()
        fig2.show()
    print('---------PPD table to LaTex-------------')
    print(PPD_per_strat.to_latex())
    print('---------************************-----\n')
    print('---------Number of trade table to LaTex-------------')
    print(numberTrades.to_latex())
    print('---------****************************-------------\n')
    pdb.set_trace()
